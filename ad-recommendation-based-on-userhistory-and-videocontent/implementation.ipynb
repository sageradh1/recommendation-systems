{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3625, 8210]\n",
      "[9848, 3102]\n",
      "(7909, 4)\n",
      "Average word count is :  1.2643823492224049\n",
      "Average watch time is :  188.69654823618663\n"
     ]
    }
   ],
   "source": [
    "################################################# Config ####################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "def get_title_from_index(index):\n",
    "\treturn df[df.index == index][\"title\"].values[0]\n",
    "\n",
    "def get_index_from_title(title):\n",
    "\treturn df[df.title == title][\"index\"].values[0]\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "#Read database and add index column if necessary\n",
    "asmidf = pd.read_csv(\"datasetasmi/uploadedVideosEdited.csv\")\n",
    "# print(asmidf.shape)\n",
    "# print(len(asmidf))\n",
    "# asmidf['index']=range(1, len(asmidf) + 1)\n",
    "asmidf.head()\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "classes = [\"Shirt\",\"Trousers\",\"Footwear\",\"Handbag\",\"Watch\",\"Guitar\",\"Mobile_phone\",\"Headphones\",\"Hat\",\"Sunglasses\"]\n",
    "\n",
    "#Create tuple list if necessary\n",
    "# alltupleList=[]\n",
    "# for i in range(0,len(asmidf)):\n",
    "#     detectedobjectsstr=str(asmidf.iloc[i]['detected_objects_withconfidence'])\n",
    "#     detectedobjectswithScore=detectedobjectsstr.split(\"|\")\n",
    "\n",
    "#     for eachobjectwithScore in detectedobjectswithScore:\n",
    "#         if eachobjectwithScore.split(\":\")[0] in classes:\n",
    "#             #( index that starts from 0 , class , score )\n",
    "#             alltupleList.append( ( i , eachobjectwithScore.split(\":\")[0],int(eachobjectwithScore.split(\":\")[1])  ) )\n",
    "\n",
    "# print(alltupleList)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#Generate a new dataframe with all the scores of detected objects\n",
    "\n",
    "currentindex=0\n",
    "def class_score(row):\n",
    "    detectedobjectsstr=str(row['detected_objects_withconfidence'])\n",
    "    detectedobjectswithScore=detectedobjectsstr.split(\"|\")\n",
    "    currentclass=classes[currentindex]\n",
    "    \n",
    "    for eachobjectwithScore in detectedobjectswithScore:\n",
    "        if eachobjectwithScore.split(\":\")[0] in classes and eachobjectwithScore.split(\":\")[0]==currentclass:\n",
    "            return int(int(eachobjectwithScore.split(\":\")[1]))\n",
    "\n",
    "# newdf=asmidf[['video_id']].copy()\n",
    "## We have not made video_id as one of the columns because video_id, which is not a feature,will also be considered \n",
    "## and used to calculate similarity matrix \n",
    "newdf = pd.DataFrame(columns = None)\n",
    "for eachclass in classes:\n",
    "    currentindex=classes.index(eachclass)\n",
    "    newdf[eachclass]=asmidf.apply(class_score,axis=1)\n",
    "\n",
    "# print(newdf.shape)\n",
    "newdf.head()\n",
    "\n",
    "# df.head()\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "#Use Cosine, if data is sparse (many ratings are undefined)\n",
    "# metric=\"cosine\"\n",
    "\n",
    "#Use Euclidean, if your data is not sparse and the magnitude of the attribute values is significant\n",
    "metric=\"euclidean\"\n",
    "\n",
    "similarity_max = 1-pairwise_distances(newdf, metric=metric)\n",
    "pd.DataFrame(similarity_max)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "#This function finds k similar video given the video_id and ratings matrix M\n",
    "#Note that the similarities are same as obtained via using pairwise_distances\n",
    "k=3\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def getvideoindexfromvideoid(video_id,matrixwithvideoid):\n",
    "#     for j in range(len(feature_matrix)):\n",
    "    for j in range(matrixwithvideoid.shape[0]):\n",
    "        if matrixwithvideoid.iloc[j]['video_id'] == video_id:\n",
    "            return j\n",
    "    return -1\n",
    "\n",
    "def getvideoidfromindex(index,matrixwithvideoid):\n",
    "    if index<=matrixwithvideoid.shape[0]:\n",
    "        return matrixwithvideoid.iloc[index]['video_id']\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def findksimilarvideo(video_id, feature_matrix,matrixwithvideoid, metric = metric, k=k):\n",
    "    similarities=[]\n",
    "    indices=[]\n",
    "    finalvideoIds=[]\n",
    "    videoindex=getvideoindexfromvideoid(video_id,matrixwithvideoid)\n",
    "    \n",
    "#     print(\"video_id: {}\".format(video_id))\n",
    "#     print(\"videoindex: {}\".format(videoindex))\n",
    "    if videoindex==-1:\n",
    "        print(\"Row with the video_id {} wasnot found.\".format(video_id))\n",
    "        return finalvideoIds\n",
    "    \n",
    "    model_knn = NearestNeighbors(metric = metric, algorithm = 'brute') \n",
    "    model_knn.fit(feature_matrix)\n",
    "    \n",
    "    distances, indices = model_knn.kneighbors(feature_matrix.iloc[videoindex, :].values.reshape(1, -1), n_neighbors = k+1)\n",
    "    similarities = 1-distances.flatten()\n",
    "#     print(\"Similarity coefficient : \",similarities)\n",
    "#     print(\"Index for similarity   : \",indices.flatten())\n",
    "    \n",
    "#     print('{0} most similar videos for Video {1}:\\n'.format(k,video_id))\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(indices.flatten())):\n",
    "        if indices.flatten()[i] == videoindex:\n",
    "            continue;\n",
    "        else:\n",
    "            requiredvideoId = getvideoidfromindex(indices.flatten()[i],matrixwithvideoid)\n",
    "            finalvideoIds.append(requiredvideoId)\n",
    "#             print('video_index:{0} video_id:{1} with similarity of {2}'.format( indices.flatten()[i],requiredvideoId,similarities.flatten()[i]))\n",
    "            \n",
    "    return finalvideoIds\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "\n",
    "# allvideoIds = findksimilarvideo(48,newdf,asmidf, metric='euclidean',k=4)\n",
    "# print(allvideoIds)\n",
    "\n",
    "allvideoIds = findksimilarvideo(5336,newdf,asmidf, metric='euclidean',k=2)\n",
    "print(allvideoIds)\n",
    "allvideoIds = findksimilarvideo(7828,newdf,asmidf, metric='euclidean',k=2)\n",
    "print(allvideoIds)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "###################################Find which video was significant for the user#########################\n",
    "\n",
    "#Read database and add index column if necessary\n",
    "view_history_raw_df = pd.read_csv(\"datasetasmi/userViewHistories.csv\")\n",
    "# print(asmidf.shape)\n",
    "# print(len(asmidf))\n",
    "# asmidf['index']=range(1, len(asmidf) + 1)\n",
    "view_history_raw_df.head()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "#Generate new dataframe with WatchCount(watch_count)\n",
    "\n",
    "# sorted_view_history_rawdf = view_history_raw_df.sort_values(by=['watched_video_id'], ascending=True)\n",
    "# print(sorted_view_history_rawdf)\n",
    "\n",
    "unique_user_id_list =view_history_raw_df.user_id.unique()\n",
    "unique_video_id_list =view_history_raw_df.watched_video_id.unique()\n",
    "# print(len(unique_user_id_list))\n",
    "# print(len(unique_video_id_list))\n",
    "\n",
    "counter=0\n",
    "# featured_view_history = pd.DataFrame(columns = ['user_id','watched_video_id','watch_count','total_watch_time'])\n",
    "\n",
    "allrowsList=[]\n",
    "for eachvideoid in unique_video_id_list:\n",
    "    for eachuserid in unique_user_id_list:\n",
    "        #Check conditions\n",
    "        rowsthatsatisfy = view_history_raw_df[(view_history_raw_df['watched_video_id']==eachvideoid) & (view_history_raw_df['user_id']==eachuserid)]\n",
    "#         print(rowsthatsatisfy)\n",
    "        count=len(rowsthatsatisfy)\n",
    "#         print(count)\n",
    "        if count==0:\n",
    "            continue\n",
    "        totalwatchtime=rowsthatsatisfy['watch_time_in_sec'].sum()\n",
    "        rowdict={'user_id':eachuserid,'watched_video_id':eachvideoid,'watch_count':count,'total_watch_time':totalwatchtime}\n",
    "        allrowsList.append(rowdict.copy())\n",
    "featured_view_history = pd.DataFrame(allrowsList)\n",
    "# featured_view_history.head()\n",
    "print(featured_view_history.shape)\n",
    "\n",
    "# featured_view_history = featured_view_history.sort_values(by=['watched_video_id'], ascending=True)\n",
    "featured_view_history.head()\n",
    "\n",
    "\n",
    "# #Check conditions\n",
    "# rowsthatsatisfy = view_history_raw_df[(view_history_raw_df['watched_video_id']==49) & (view_history_raw_df['user_id']==1)]\n",
    "# print(rowsthatsatisfy)\n",
    "# count=len(rowsthatsatisfy)\n",
    "# print(count)\n",
    "# totalwatchtime=rowsthatsatisfy['watch_time_in_sec'].sum()\n",
    "# print(totalwatchtime)\n",
    "\n",
    "\n",
    "\n",
    "##############add rows to dataframe\n",
    "\n",
    "# rows_list = []\n",
    "# for row in input_rows:\n",
    "\n",
    "#         dict1 = {}\n",
    "#         # get input row in dictionary format\n",
    "#         # key = col_name\n",
    "#         dict1.update(blah..) \n",
    "\n",
    "#         rows_list.append(dict1)\n",
    "# df = pd.DataFrame(rows_list)\n",
    "\n",
    "\n",
    "# rows_list = [{'id':99 , 'user_id':1 , 'watched_video_id':20 , 'watch_time_in_sec':50 },{'id':199 , 'user_id':2 , 'watched_video_id':40 , 'watch_time_in_sec':100 }]\n",
    "# df = pd.DataFrame(rows_list)\n",
    "# df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# currentindex=0\n",
    "# def class_score(row):\n",
    "#     detectedobjectsstr=str(row['detected_objects_withconfidence'])\n",
    "#     detectedobjectswithScore=detectedobjectsstr.split(\"|\")\n",
    "#     currentclass=classes[currentindex]\n",
    "    \n",
    "#     for eachobjectwithScore in detectedobjectswithScore:\n",
    "#         if eachobjectwithScore.split(\":\")[0] in classes and eachobjectwithScore.split(\":\")[0]==currentclass:\n",
    "#             return int(int(eachobjectwithScore.split(\":\")[1]))\n",
    "\n",
    "# # newdf=asmidf[['video_id']].copy()\n",
    "# newdf = pd.DataFrame(columns = None)\n",
    "# for eachclass in classes:\n",
    "#     currentindex=classes.index(eachclass)\n",
    "#     newdf[eachclass]=asmidf.apply(class_score,axis=1)\n",
    "\n",
    "# # print(newdf.shape)\n",
    "# newdf.head()\n",
    "\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "#Normalise the data according to average\n",
    "word_count_avg=featured_view_history['watch_count'].mean()\n",
    "watch_time_avg=featured_view_history['total_watch_time'].mean()\n",
    "print(\"Average word count is : \",word_count_avg)\n",
    "print(\"Average watch time is : \",watch_time_avg)\n",
    "\n",
    "currentindex=0\n",
    "current_class_name=''\n",
    "def avg_out_score(row):\n",
    "    return row[current_class_name]/avgList_forcolumns[currentindex]\n",
    "\n",
    "columnsToBeNormalised=['watch_count','total_watch_time']\n",
    "avgList_forcolumns = [word_count_avg,watch_time_avg]\n",
    "\n",
    "normalisedf=featured_view_history[['user_id','watched_video_id','total_watch_time']].copy()\n",
    "\n",
    "# normaliseddf = pd.DataFrame(columns = None)\n",
    "for eachclass in columnsToBeNormalised:\n",
    "    current_class_name=eachclass\n",
    "    currentindex=columnsToBeNormalised.index(eachclass)\n",
    "    normalisedf['avg_'+eachclass]=featured_view_history.apply(avg_out_score,axis=1)\n",
    "\n",
    "watch_time_importance = 0.7\n",
    "watch_count_importance = 0.3\n",
    "\n",
    "def calculate_video_importance(row):\n",
    "    return row['avg_watch_count']*watch_count_importance*row['avg_total_watch_time']*watch_time_importance\n",
    "\n",
    "normalisedf['video_importance']=normalisedf.apply(calculate_video_importance,axis=1)\n",
    "\n",
    "# normalisedf = normalisedf.sort_values(by=['video_importance'], ascending=False)\n",
    "normalisedf.head()\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "##Find most important video\n",
    "number_of_video=3\n",
    "\n",
    "def findmostimportantvideo(user_id,dataframe,number_of_video=number_of_video):\n",
    "    dataframe=dataframe[dataframe['user_id']==user_id]\n",
    "    dataframe=dataframe.sort_values(by=['video_importance'], ascending=False)\n",
    "    return dataframe.head(number_of_video)['watched_video_id'].values\n",
    "\n",
    "def loadvideofeaturesdf_videoiddf():\n",
    "    return newdf,asmidf,normalisedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### LOADED DF ASSIGNMENT #####################################################\n",
    "\n",
    "# classes = [\"Shirt\",\"Trousers\",\"Footwear\",\"Handbag\",\"Watch\",\"Guitar\",\"Mobile_phone\",\"Headphones\",\"Hat\",\"Sunglasses\"]\n",
    "\n",
    "VIDEO_WITH_FEATURES_DF, MATRIX_WITH_VIDEOID,USERVIEWNORMALISEDDF=loadvideofeaturesdf_videoiddf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>watched_video_id</th>\n",
       "      <th>total_watch_time</th>\n",
       "      <th>avg_watch_count</th>\n",
       "      <th>avg_total_watch_time</th>\n",
       "      <th>video_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9195</td>\n",
       "      <td>74</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.392164</td>\n",
       "      <td>0.065134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7331</td>\n",
       "      <td>143</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.757831</td>\n",
       "      <td>0.125867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8403</td>\n",
       "      <td>21</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.111290</td>\n",
       "      <td>0.018484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>8403</td>\n",
       "      <td>192</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>1.017507</td>\n",
       "      <td>0.168997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6903</td>\n",
       "      <td>488</td>\n",
       "      <td>1.5818</td>\n",
       "      <td>2.586163</td>\n",
       "      <td>0.859066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  watched_video_id  total_watch_time  avg_watch_count  \\\n",
       "0        1              9195                74           0.7909   \n",
       "1        1              7331               143           0.7909   \n",
       "2        1              8403                21           0.7909   \n",
       "3        2              8403               192           0.7909   \n",
       "4        2              6903               488           1.5818   \n",
       "\n",
       "   avg_total_watch_time  video_importance  \n",
       "0              0.392164          0.065134  \n",
       "1              0.757831          0.125867  \n",
       "2              0.111290          0.018484  \n",
       "3              1.017507          0.168997  \n",
       "4              2.586163          0.859066  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIDEO_WITH_FEATURES_DF.head()\n",
    "MATRIX_WITH_VIDEOID.head()\n",
    "USERVIEWNORMALISEDDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5336]\n",
      "[5336, 3625]\n",
      "[('Shirt', 2.0), ('Trousers', 7.5), ('Footwear', 1.0), ('Handbag', 7.0), ('Watch', 4.0), ('Guitar', 9.0), ('Mobile_phone', 4.0), ('Headphones', 4.0), ('Hat', 10.0), ('Sunglasses', 6.5)]\n",
      "[('Shirt', 8.0), ('Trousers', 10.0), ('Footwear', 7.0), ('Handbag', 2.0), ('Watch', 9.0), ('Guitar', 5.0), ('Mobile_phone', 3.0), ('Headphones', 4.0), ('Hat', 6.0), ('Sunglasses', 1.0)]\n",
      "[('Shirt', 5.0), ('Trousers', 8.75), ('Footwear', 4.0), ('Handbag', 4.5), ('Watch', 6.5), ('Guitar', 7.0), ('Mobile_phone', 3.5), ('Headphones', 4.0), ('Hat', 8.0), ('Sunglasses', 3.75)]\n",
      "[('Trousers', 8.75), ('Hat', 8.0), ('Guitar', 7.0), ('Watch', 6.5), ('Shirt', 5.0), ('Handbag', 4.5), ('Footwear', 4.0), ('Headphones', 4.0), ('Sunglasses', 3.75), ('Mobile_phone', 3.5)]\n",
      "['Shirt', 'Trousers']\n"
     ]
    }
   ],
   "source": [
    "############################################# APP-PAGE SIDE LOGIC #####################################################\n",
    "current_user_id=1\n",
    "current_beingwatched_video_id=48\n",
    "number_of_history_based_imp_videoid = 1\n",
    "\n",
    "# find important videos according to who the user is and his views history \n",
    "requiredVideoIDList = findmostimportantvideo(current_user_id,USERVIEWNORMALISEDDF,number_of_video=number_of_history_based_imp_videoid)\n",
    "print(requiredVideoIDList)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# Make a list of similar videos including important videos\n",
    "\n",
    "similar_videos_list=[]\n",
    "number_of_similar_videos=1\n",
    "\n",
    "for i in range(len(requiredVideoIDList)):\n",
    "    current_video_id = requiredVideoIDList[i]\n",
    "    similar_videos_list.append(current_video_id)\n",
    "    allvideoIds = findksimilarvideo(current_video_id,VIDEO_WITH_FEATURES_DF,MATRIX_WITH_VIDEOID, metric='euclidean',k=number_of_similar_videos)\n",
    "    for j in range(len(allvideoIds)):\n",
    "        similar_videos_list.append(allvideoIds[j])\n",
    "\n",
    "# If I had to recommend new video...I would recommend these without appending current_video_id as they had been already watched\n",
    "print(similar_videos_list)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "#### Extract important features from the videoid\n",
    "## First use already available VIDEO_WITH_FEATURES_DF for 'FEATURES' and MATRIX_WITH_VIDEOID for \"VIDEO_ID\" to make matrix_with_bothFeatureAndVideoId\n",
    "\n",
    "matrix_with_bothFeatureAndVideoId = VIDEO_WITH_FEATURES_DF.copy()\n",
    "matrix_with_bothFeatureAndVideoId['video_id']= MATRIX_WITH_VIDEOID['video_id']\n",
    "matrix_with_bothFeatureAndVideoId.head()\n",
    "\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "\n",
    "# matrix_with_bothFeatureAndVideoId=matrix_with_bothFeatureAndVideoId[matrix_with_bothFeatureAndVideoId['video_id'] in similar_videos_list]\n",
    "filtered_df = matrix_with_bothFeatureAndVideoId.loc[matrix_with_bothFeatureAndVideoId['video_id'].isin(similar_videos_list)]\n",
    "filtered_df.head()\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "listoffeatures = filtered_df.columns.tolist()\n",
    "listoffeatures.remove('video_id')\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "##### MAIN SCORES TUPLE FROM USER HISTORY\n",
    "features_withscores_from_userhistory = []\n",
    "\n",
    "def make_required_tuple_from_df(listoffeatures,df=filtered_df):\n",
    "    features_withscores=[]\n",
    "    for i in range(len(listoffeatures)):\n",
    "        currentfeature = listoffeatures[i]\n",
    "        currentfeaturescore = df[currentfeature].mean()\n",
    "        features_withscores.append((currentfeature,currentfeaturescore))\n",
    "    return features_withscores\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "features_withscores_from_userhistory=make_required_tuple_from_df(listoffeatures,df=filtered_df)\n",
    "print(features_withscores_from_userhistory)\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "######## LETS START EXTRACTING AVAILABLE FEATURE FROM CURRENT VIDEO THAT USER IS WATCHING\n",
    "\n",
    "filtered_df = matrix_with_bothFeatureAndVideoId.loc[matrix_with_bothFeatureAndVideoId['video_id']==current_beingwatched_video_id]\n",
    "\n",
    "listoffeatures = filtered_df.columns.tolist()\n",
    "listoffeatures.remove('video_id')\n",
    "listoffeatures\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "## Make tuple as above:\n",
    "features_withscores_from_videocontent =make_required_tuple_from_df(listoffeatures,df=filtered_df)\n",
    "print(features_withscores_from_videocontent)\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "### Till now\n",
    "# From userhistory,  we got  features_withscores_from_userhistory\n",
    "# From videocontent, we got  features_withscores_from_videocontent\n",
    "\n",
    "significance_of_userhistory  = 0.5\n",
    "significance_of_videocontent = 0.5\n",
    "\n",
    "def getindexfromTupleListbasedonfeature(featurename,tuplename):\n",
    "#     for j in range(len(feature_matrix)):\n",
    "    for j in range(len(tuplename)):\n",
    "        if tuplename[j][0] == featurename:\n",
    "            return j\n",
    "    return -1\n",
    "\n",
    "avgout_feature_score=[]\n",
    "for i in range(len(listoffeatures)):\n",
    "    currentfeature = listoffeatures[i]\n",
    "    valuefrom_userhistory = features_withscores_from_userhistory[getindexfromTupleListbasedonfeature(currentfeature,features_withscores_from_userhistory)][1]\n",
    "    valuefrom_videocontent = features_withscores_from_videocontent[getindexfromTupleListbasedonfeature(currentfeature,features_withscores_from_videocontent)][1]\n",
    "    average = valuefrom_userhistory * significance_of_userhistory + valuefrom_videocontent * significance_of_videocontent\n",
    "    avgout_feature_score.append((currentfeature,average))\n",
    "\n",
    "print(avgout_feature_score)\n",
    "\n",
    "sorted_avgout_feature_score = sorted(avgout_feature_score, key=lambda k: k[1],reverse=True)\n",
    "print(sorted_avgout_feature_score)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "## Function that gets top scoring ads\n",
    "\n",
    "def getNamesofTopScoringAdsFromTupleOfAverage(numberofads,avg_tuple):\n",
    "    adnames = []\n",
    "    for i in range(numberofads):\n",
    "        adnames.append(avg_tuple[i][0])\n",
    "    return adnames\n",
    "    \n",
    "\n",
    "numberofadstobeshown = 2\n",
    "nameofads = getNamesofTopScoringAdsFromTupleOfAverage(numberofadstobeshown,avgout_feature_score)\n",
    "print(nameofads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bijyabrojupyter",
   "language": "python",
   "name": "bijyabrojupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
